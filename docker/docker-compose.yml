# ===========================================================
# Zeroth — Local Development Stack (Production-Grade)
# ===========================================================
# All services use the same tooling as production.
# Profiles let you start in phases:
#
#   docker compose --profile core up -d          # Phase 1: Storage + Catalog + Query
#   docker compose --profile ingestion up -d     # Phase 2: Streaming + Data Flow
#   docker compose --profile ui up -d            # Phase 3: BI + SQL IDE
#
# After first core startup, bootstrap Polaris:
#   docker compose run --rm polaris-bootstrap
#
# UIs:
#   Superset (BI):    http://localhost:8088  (admin/admin)
#   MinIO Console:    http://localhost:9001  (admin/password123)
#   Trino Web UI:     http://localhost:8080
#   NiFi UI:          https://localhost:8443/nifi (admin/zeroth-admin-password)
# ===========================================================

services:
  # =========================================================
  #  CORE PROFILE — Storage + Catalog + Query Engine
  # =========================================================

  # ---------------------------------------------------------
  # MinIO — S3-compatible Object Storage
  # Replaces: Snowflake's internal storage layer
  # ---------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    profiles: ["core"]
    ports:
      - "9000:9000"    # S3 API
      - "9001:9001"    # Console UI
    networks:
      default:
        aliases:
          - warehouse.minio
          - iceberg.minio
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
      MINIO_REGION_NAME: us-east-1
      MINIO_DOMAIN: minio
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Create default buckets
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    profiles: ["core"]
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 admin password123;
      /usr/bin/mc mb --ignore-existing --region=us-east-1 myminio/warehouse;
      /usr/bin/mc mb --ignore-existing --region=us-east-1 myminio/iceberg;
      /usr/bin/mc anonymous set public myminio/warehouse;
      /usr/bin/mc anonymous set public myminio/iceberg;
      exit 0;
      "

  # ---------------------------------------------------------
  # PostgreSQL — Polaris Metadata Backend
  # Stores catalog metadata (tables, namespaces, privileges)
  # ---------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    container_name: polaris-db
    profiles: ["core"]
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: polaris
      POSTGRES_USER: polaris
      POSTGRES_PASSWORD: polaris123
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U polaris"]
      interval: 5s
      timeout: 3s
      retries: 5

  # ---------------------------------------------------------
  # Apache Polaris — Iceberg REST Catalog + RBAC
  # Replaces: Snowflake's Cloud Services Layer
  # Uses Quarkus with relational-jdbc persistence (PostgreSQL)
  # ---------------------------------------------------------
  polaris:
    image: apache/polaris:latest
    container_name: polaris
    profiles: ["core"]
    ports:
      - "8181:8181"    # REST Catalog API
      - "8182:8182"    # Management API
    environment:
      # Persistence — relational JDBC to PostgreSQL
      POLARIS_PERSISTENCE_TYPE: relational-jdbc
      QUARKUS_DATASOURCE_DB_KIND: postgresql
      QUARKUS_DATASOURCE_JDBC_URL: jdbc:postgresql://polaris-db:5432/polaris
      QUARKUS_DATASOURCE_USERNAME: polaris
      QUARKUS_DATASOURCE_PASSWORD: polaris123
      # Bootstrap realm
      POLARIS_BOOTSTRAP_DEFAULT_REALMS: default-realm
      # S3 / MinIO credentials for storage access
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
      AWS_REGION: us-east-1
    depends_on:
      postgres:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8182/q/health"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 20s

  # ---------------------------------------------------------
  # Polaris DB Bootstrap — Schema migration (run FIRST)
  # Creates the polaris_schema tables in PostgreSQL
  # Usage: docker compose --profile bootstrap-db run --rm polaris-db-bootstrap
  # ---------------------------------------------------------
  polaris-db-bootstrap:
    image: apache/polaris-admin-tool:latest
    container_name: polaris-db-bootstrap
    profiles: ["bootstrap-db"]
    environment:
      QUARKUS_DATASOURCE_DB_KIND: postgresql
      QUARKUS_DATASOURCE_JDBC_URL: jdbc:postgresql://polaris-db:5432/polaris
      QUARKUS_DATASOURCE_USERNAME: polaris
      QUARKUS_DATASOURCE_PASSWORD: polaris123
      POLARIS_BOOTSTRAP_DEFAULT_REALMS: default-realm
    command: ["bootstrap", "--realm=POLARIS", "--credential=POLARIS,root,polaris", "--print-credentials"]
    depends_on:
      postgres:
        condition: service_healthy

  # ---------------------------------------------------------
  # Polaris Catalog Bootstrap — Create catalog, roles, grants
  # Usage: docker compose --profile bootstrap run --rm polaris-bootstrap
  # ---------------------------------------------------------
  polaris-bootstrap:
    image: alpine:3.20
    container_name: polaris-bootstrap
    profiles: ["bootstrap"]
    environment:
      POLARIS_HOST: polaris
      POLARIS_PORT: "8181"
      POLARIS_MGMT_PORT: "8182"
      MINIO_ENDPOINT: http://minio:9000
    volumes:
      - ../scripts/bootstrap-polaris.sh:/bootstrap.sh:ro
    entrypoint: ["sh", "-c", "apk add --no-cache curl jq > /dev/null 2>&1 && sh /bootstrap.sh"]
    depends_on:
      polaris:
        condition: service_healthy

  # ---------------------------------------------------------
  # Trino — Distributed SQL Query Engine
  # Replaces: Snowflake's Virtual Warehouses
  # ---------------------------------------------------------
  trino:
    image: trinodb/trino:latest
    container_name: trino
    profiles: ["core"]
    ports:
      - "8080:8080"    # Trino Web UI + JDBC
    environment:
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
      AWS_REGION: us-east-1
    volumes:
      - ../configs/trino/iceberg.properties:/etc/trino/catalog/iceberg.properties
    depends_on:
      polaris:
        condition: service_healthy

  # =========================================================
  #  INGESTION PROFILE — Streaming + Data Flow
  # =========================================================

  # ---------------------------------------------------------
  # Redpanda — Kafka-compatible Event Streaming (C++, no JVM)
  # Drop-in replacement for Kafka with ~10x less memory usage
  # ---------------------------------------------------------
  redpanda:
    image: redpandadata/redpanda:latest
    container_name: redpanda
    profiles: ["ingestion"]
    command:
      - redpanda start
      - --smp 1
      - --memory 256M
      - --overprovisioned
      - --node-id 0
      - --kafka-addr PLAINTEXT://0.0.0.0:9092
      - --advertise-kafka-addr PLAINTEXT://redpanda:9092
      - --pandaproxy-addr 0.0.0.0:8082
      - --advertise-pandaproxy-addr redpanda:8082
    ports:
      - "9092:9092"     # Kafka API (wire-compatible)
      - "8082:8082"     # HTTP Proxy API
    volumes:
      - redpanda-data:/var/lib/redpanda/data
    healthcheck:
      test: ["CMD", "rpk", "cluster", "health"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 10s

  # ---------------------------------------------------------
  # Apache NiFi — Visual Data Flow Engine
  # ---------------------------------------------------------
  nifi:
    image: apache/nifi:latest
    container_name: nifi
    profiles: ["ingestion"]
    ports:
      - "8443:8443"
    environment:
      NIFI_WEB_HTTPS_PORT: "8443"
      SINGLE_USER_CREDENTIALS_USERNAME: admin
      SINGLE_USER_CREDENTIALS_PASSWORD: zeroth-admin-password
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
    volumes:
      - nifi-data:/opt/nifi/nifi-current/conf
    depends_on:
      redpanda:
        condition: service_healthy

  # ---------------------------------------------------------
  # Redpanda Console — Web UI for Topics & Consumer Groups
  # ---------------------------------------------------------
  redpanda-console:
    image: redpandadata/console:latest
    container_name: redpanda-console
    profiles: ["ingestion"]
    ports:
      - "8084:8080"
    environment:
      KAFKA_BROKERS: redpanda:9092
    depends_on:
      redpanda:
        condition: service_healthy

  # =========================================================
  #  UI PROFILE — BI & SQL IDE
  # =========================================================

  # ---------------------------------------------------------
  # Redis — Superset cache backend
  # ---------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: redis
    profiles: ["ui"]
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    profiles: ["ui"]
    environment:
      # This tells the UI exactly where your Redis container lives on the Docker network
      - REDIS_HOSTS=zeroth-cache:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis

  # ---------------------------------------------------------
  # Superset Metadata DB
  # ---------------------------------------------------------
  superset-db:
    image: postgres:16-alpine
    container_name: superset-db
    profiles: ["ui"]
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: superset
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: superset123
    volumes:
      - superset-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superset"]
      interval: 5s
      timeout: 3s
      retries: 5

  # ---------------------------------------------------------
  # Apache Superset — BI & SQL IDE
  # Replaces: Snowsight (web UI, dashboards, SQL worksheets)
  # ---------------------------------------------------------
  superset:
    image: apache/superset:latest
    container_name: superset
    profiles: ["ui"]
    user: root
    ports:
      - "8088:8088"
    environment:
      SUPERSET_CONFIG_PATH: /app/superset_config.py
      SUPERSET_SECRET_KEY: "zeroth-superset-secret-key-change-in-prod"
    volumes:
      - ../configs/superset/superset_config.py:/app/superset_config.py:ro
    depends_on:
      superset-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 60s
    command: >
      /bin/sh -c "
        uv pip install psycopg2-binary 'trino[sqlalchemy]' 2>/dev/null;
        /app/.venv/bin/superset db upgrade;
        /app/.venv/bin/superset fab create-admin --username admin --firstname Zeroth --lastname Admin --email admin@zeroth.local --password admin || true;
        /app/.venv/bin/superset init;
        /app/.venv/bin/superset run -h 0.0.0.0 -p 8088 --with-threads
      "
  superset-worker:
    image: apache/superset:latest
    container_name: superset-worker
    profiles: ["ui"]
    user: root
    environment:
      SUPERSET_CONFIG_PATH: /app/superset_config.py
      SUPERSET_SECRET_KEY: "zeroth-superset-secret-key-change-in-prod"
    volumes:
      - ../configs/superset/superset_config.py:/app/superset_config.py:ro
    depends_on:
      superset-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: >
      /bin/sh -c "
        uv pip install psycopg2-binary 'trino[sqlalchemy]' 2>/dev/null;
        /app/.venv/bin/celery --app=superset.tasks.celery_app:app worker -O fair -c 4
      "
  superset-flower:
    image: apache/superset:latest
    container_name: superset-flower
    profiles: ["ui"]
    user: root
    ports:
      - "5555:5555"
    environment:
      SUPERSET_CONFIG_PATH: /app/superset_config.py
      # Flower needs to know where the broker (Redis) is
      CELERY_BROKER_URL: redis://redis:6379/0
    volumes:
      - ../configs/superset/superset_config.py:/app/superset_config.py:ro
    depends_on:
      redis:
        condition: service_healthy
      superset-worker:
        condition: service_started
    command: >
      /bin/sh -c "
        uv pip install psycopg2-binary flower redis 2>/dev/null;
        /app/.venv/bin/celery --app=superset.tasks.celery_app:app flower --port=5555
      "

volumes:
  minio-data:
  postgres-data:
  redpanda-data:
  nifi-data:
  redis-data:
  superset-db-data:
